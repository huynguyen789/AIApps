{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/huyknguyen/Desktop/redhorse/code_projects/ai_apps/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!python -m pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# anthropic pdf reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install --upgrade anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 2025 calendar for RedHorse company that shows:\n",
      "\n",
      "Paydays: Marked with red circles, occurring approximately twice per month\n",
      "- Timesheets are due on the last day of pay periods (1st-15th and 16th-last day of month)\n",
      "- If the last day falls on a weekend or holiday, timesheets are due the Friday before\n",
      "\n",
      "Company Paid Holidays: Marked in blue shading, including dates like:\n",
      "- January 20\n",
      "- February 17\n",
      "- April 7\n",
      "- May 26\n",
      "- July 4\n",
      "- September 1\n",
      "- October 13\n",
      "- November 27\n",
      "- December 25\n",
      "\n",
      "The calendar clearly marks both paydays and holidays throughout all 12 months of 2025, helping employees track important dates for timesheet submissions and paid time off.\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_pdf(pdf_path, question):\n",
    "    \"\"\"\n",
    "    Input: Path to PDF file and question to ask about the PDF\n",
    "    Process: Reads PDF, encodes it, and sends to Claude API\n",
    "    Output: Claude's response about the PDF\n",
    "    \"\"\"\n",
    "    # Read and encode PDF\n",
    "    pdf_data = base64.b64encode(Path(pdf_path).read_bytes()).decode(\"utf-8\")\n",
    "    \n",
    "    # Initialize Claude client\n",
    "    client = anthropic.Anthropic()\n",
    "    \n",
    "    # Create message request\n",
    "    message = client.beta.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        betas=[\"pdfs-2024-09-25\"],\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"document\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"application/pdf\",\n",
    "                            \"data\": pdf_data\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": question\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # Simply return the text content\n",
    "    return message.content[0].text\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"/Users/huyknguyen/Desktop/redhorse/code_projects/ai_apps/docs/redhorse_docs/2024:10:2025-Workweek-Calendar.pdf\"\n",
    "question = \"Please summarize the key dates and information from this calendar.\"\n",
    "\n",
    "try:\n",
    "    response = analyze_pdf(pdf_path, question)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai audio output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-audio-preview\",\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Is a golden retriever a good family dog?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0])\n",
    "\n",
    "wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)\n",
    "with open(\"dog.wav\", \"wb\") as f:\n",
    "    f.write(wav_bytes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import streamlit as st\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to generate audio response\n",
    "def generate_audio_response(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-audio-preview\",\n",
    "        modalities=[\"text\", \"audio\"],\n",
    "        audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0]\n",
    "\n",
    "# Function to decode and save audio\n",
    "def save_audio(audio_data, filename):\n",
    "    wav_bytes = base64.b64decode(audio_data)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(wav_bytes)\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Multi-turn Conversation Bot\")\n",
    "\n",
    "# User input\n",
    "user_input = st.text_input(\"You: \", \"\")\n",
    "\n",
    "if user_input:\n",
    "    # Add user message to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Generate response\n",
    "    response = generate_audio_response(conversation_history)\n",
    "\n",
    "    # Add assistant message to conversation history\n",
    "    conversation_history.append(response.message)\n",
    "\n",
    "    # Save and play audio\n",
    "    audio_filename = f\"{response.message.audio.id}.wav\"\n",
    "    save_audio(response.message.audio.data, audio_filename)\n",
    "    st.audio(audio_filename, format=\"audio/wav\", autoplay=True)\n",
    "\n",
    "    # Display transcript\n",
    "    st.write(\"Assistant: \", response.message.audio.transcript)\n",
    "\n",
    "# Display conversation history\n",
    "st.subheader(\"Conversation History\")\n",
    "for message in conversation_history:\n",
    "    if isinstance(message, dict):  # User message\n",
    "        role = \"You\"\n",
    "        content = message[\"content\"]\n",
    "    else:  # Assistant message\n",
    "        role = \"Assistant\"\n",
    "        content = message.audio.transcript\n",
    "    st.write(f\"{role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elevenlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffe8e309-cb36-462a-a88d-fe7538a01d3a.mp3: A new audio file was saved successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ffe8e309-cb36-462a-a88d-fe7538a01d3a.mp3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import uuid\n",
    "from elevenlabs import VoiceSettings\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "client = ElevenLabs(\n",
    "    api_key=ELEVENLABS_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "def text_to_speech_file(text: str) -> str:\n",
    "    # Calling the text_to_speech conversion API with detailed parameters\n",
    "    response = client.text_to_speech.convert(\n",
    "        voice_id=\"pNInz6obpgDQGcFmaJgB\", # Adam pre-made voice\n",
    "        output_format=\"mp3_22050_32\",\n",
    "        text=text,\n",
    "        model_id=\"eleven_turbo_v2_5\", # use the turbo model for low latency\n",
    "        voice_settings=VoiceSettings(\n",
    "            stability=0.0,\n",
    "            similarity_boost=1.0,\n",
    "            style=0.0,\n",
    "            use_speaker_boost=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # uncomment the line below to play the audio back\n",
    "    # play(response)\n",
    "\n",
    "    # Generating a unique file name for the output MP3 file\n",
    "    save_file_path = f\"{uuid.uuid4()}.mp3\"\n",
    "\n",
    "    # Writing the audio to a file\n",
    "    with open(save_file_path, \"wb\") as f:\n",
    "        for chunk in response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    print(f\"{save_file_path}: A new audio file was saved successfully!\")\n",
    "\n",
    "    # Return the path of the saved audio file\n",
    "    return save_file_path\n",
    "\n",
    "text_to_speech_file(\"Hello World\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
