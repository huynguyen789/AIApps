{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install docx2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \n",
      "\n",
      "\n",
      "\n",
      "Monthly Status Report # --\n",
      "\n",
      "HQ0034-20-F-0237\n",
      "Task Order 4\n",
      "Leased Facilities Division (LFD)\n",
      "Administrative and Financial Services Support\n",
      "\n",
      "\n",
      "\n",
      "For Work Performed:\n",
      "\n",
      "September\n",
      "2024 \n",
      "\n",
      "Submitted to:\n",
      "\n",
      "Mrs. Tina Hall  \n",
      "Contracting Officer’s Representative\n",
      "Washington Headquarters Service (WHS)\n",
      "Acquisition Directorate (AD)\n",
      "1155 Defense Pentagon Room 5B951\n",
      "Washington, DC \n",
      "20301-1155\n",
      "Tina.m.hall70.civ@mail.mil\n",
      "\n",
      "(202) 819 - 2679\n",
      "\n",
      "Submitted by:\n",
      "\n",
      "Adrian Nicholas\n",
      "Redhorse Corporation\n",
      "1777 N. Kent St, Suite 1200\n",
      "Arlington, VA 22209 \n",
      "adrian.nicholas@redhorsecorp.com \n",
      "(347) 204-8125\n",
      "Administrative and Financial Services Support Team:\n",
      "Eddy Biniam \n",
      "Miguel Vega\n",
      "\n",
      "Work Performed During MONTH YEAR \n",
      "Administrative Services Support\n",
      "\n",
      "Financial Services Support\n",
      "Assisted a colleague of mine in gathering necessary 3 DAI reports and 1 Maximo report in order to send out a Cost Transfer in a timely fashion.\n",
      "Completed a hot item that my Supervisor and lead needed immediately. Did a contract PR’s for a CMTSS contract for goods. I was able to demonstrate the ability to remain calm and focused under pressure and submit the document without any mistakes so the document can be signed as soon as possible. I stayed until the task was completed and supervisor was informed. \n",
      "Worked on looking the Status of Funds for FY22 as well as FY23 and verify that there was no funds remaining. Upon acceding DAI and get gathering the data, not only did I communicate with my supervisor my findings but I edit the Status of Funds data so my supervisor can see and read the information gather in a manner that is easy to read. \n",
      "Completed 2 contract PRs for goods for 20K. I was able to provide a solution to my supervisor. One of my colleagues who was in charge or creating those PRs continued to get an error message. I was able to create 2 PRs with my supervisor looking on correctly in order to see if they can see it in PD2. Which the creation of the PR’s was a success and was able to be seen in PD2. Since it is the close of the FY we could not afford to delay due to in-corrections. The corrections was able to be made and not delay the process. \n",
      "Worked on assisting my supervisor on looking for a specific MIPR that was on the Open Commitment Pivot Tables I pull and create every morning. I was provided the correct email chain and cc’d the correct emails so the agency (DLA) could be provided with the correct MIPR that they were requesting. It was of up most importance for the agency to receive that MIPR so we can receive and process the 448-2 acceptance with urgency. \n",
      " \n",
      "Deliverables Completed\n",
      "\n",
      "\n",
      "Highlights\n",
      "\n",
      "\n",
      "Issues/Resolutions\n",
      "Issue:  \n",
      "Resolution:  \n",
      "\n",
      "Planned Work for Next Two Months\n",
      "Administrative Services Support\n",
      " \n",
      "\n",
      "Financial Services Support\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Leave:\n",
      "\n",
      "\n",
      "Recommendations: \n",
      "None\n",
      "Contractual/Staffing Actions:\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "\n",
    "def read_file(file):\n",
    "    if isinstance(file, str):\n",
    "        file_path = file\n",
    "    else:\n",
    "        file_path = file.name\n",
    "\n",
    "    if file_path.endswith('.docx'):\n",
    "        doc = docx.Document(file_path)\n",
    "        full_text = []\n",
    "        for element in doc.element.body:\n",
    "            if element.tag.endswith('p'):\n",
    "                full_text.append(element.text)\n",
    "            elif element.tag.endswith('tbl'):\n",
    "                table = []\n",
    "                for row in element.findall('.//w:tr', namespaces=element.nsmap):\n",
    "                    cells = [cell.text for cell in row.findall('.//w:t', namespaces=element.nsmap)]\n",
    "                    table.append(' | '.join(cells))\n",
    "                full_text.append('\\n'.join(table))\n",
    "        return '\\n'.join(full_text)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"/Users/huyknguyen/Desktop/redhorse/code_projects/ai_apps/docs/MSR/Eddy Biniam MSR Template.docx\"\n",
    "content = read_file(file_path)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai audio output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-audio-preview\",\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Is a golden retriever a good family dog?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0])\n",
    "\n",
    "wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)\n",
    "with open(\"dog.wav\", \"wb\") as f:\n",
    "    f.write(wav_bytes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import streamlit as st\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to generate audio response\n",
    "def generate_audio_response(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-audio-preview\",\n",
    "        modalities=[\"text\", \"audio\"],\n",
    "        audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0]\n",
    "\n",
    "# Function to decode and save audio\n",
    "def save_audio(audio_data, filename):\n",
    "    wav_bytes = base64.b64decode(audio_data)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(wav_bytes)\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Multi-turn Conversation Bot\")\n",
    "\n",
    "# User input\n",
    "user_input = st.text_input(\"You: \", \"\")\n",
    "\n",
    "if user_input:\n",
    "    # Add user message to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Generate response\n",
    "    response = generate_audio_response(conversation_history)\n",
    "\n",
    "    # Add assistant message to conversation history\n",
    "    conversation_history.append(response.message)\n",
    "\n",
    "    # Save and play audio\n",
    "    audio_filename = f\"{response.message.audio.id}.wav\"\n",
    "    save_audio(response.message.audio.data, audio_filename)\n",
    "    st.audio(audio_filename, format=\"audio/wav\", autoplay=True)\n",
    "\n",
    "    # Display transcript\n",
    "    st.write(\"Assistant: \", response.message.audio.transcript)\n",
    "\n",
    "# Display conversation history\n",
    "st.subheader(\"Conversation History\")\n",
    "for message in conversation_history:\n",
    "    if isinstance(message, dict):  # User message\n",
    "        role = \"You\"\n",
    "        content = message[\"content\"]\n",
    "    else:  # Assistant message\n",
    "        role = \"Assistant\"\n",
    "        content = message.audio.transcript\n",
    "    st.write(f\"{role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elevenlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffe8e309-cb36-462a-a88d-fe7538a01d3a.mp3: A new audio file was saved successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ffe8e309-cb36-462a-a88d-fe7538a01d3a.mp3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import uuid\n",
    "from elevenlabs import VoiceSettings\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "client = ElevenLabs(\n",
    "    api_key=ELEVENLABS_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "def text_to_speech_file(text: str) -> str:\n",
    "    # Calling the text_to_speech conversion API with detailed parameters\n",
    "    response = client.text_to_speech.convert(\n",
    "        voice_id=\"pNInz6obpgDQGcFmaJgB\", # Adam pre-made voice\n",
    "        output_format=\"mp3_22050_32\",\n",
    "        text=text,\n",
    "        model_id=\"eleven_turbo_v2_5\", # use the turbo model for low latency\n",
    "        voice_settings=VoiceSettings(\n",
    "            stability=0.0,\n",
    "            similarity_boost=1.0,\n",
    "            style=0.0,\n",
    "            use_speaker_boost=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # uncomment the line below to play the audio back\n",
    "    # play(response)\n",
    "\n",
    "    # Generating a unique file name for the output MP3 file\n",
    "    save_file_path = f\"{uuid.uuid4()}.mp3\"\n",
    "\n",
    "    # Writing the audio to a file\n",
    "    with open(save_file_path, \"wb\") as f:\n",
    "        for chunk in response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    print(f\"{save_file_path}: A new audio file was saved successfully!\")\n",
    "\n",
    "    # Return the path of the saved audio file\n",
    "    return save_file_path\n",
    "\n",
    "text_to_speech_file(\"Hello World\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
