{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install docx2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \n",
      "\n",
      "\n",
      "\n",
      "Monthly Status Report # --\n",
      "\n",
      "HQ0034-20-F-0208\n",
      "Task Order 1\n",
      "Federal Facilities Division (FFD)\n",
      "Administrative, Financial and Professional Support Services \n",
      "\n",
      "\n",
      "\n",
      "For Work Performed\n",
      "\n",
      "MONTH YEAR\n",
      "\n",
      "Submitted to:\n",
      "\n",
      "Mrs. Tina Hall  \n",
      "Contracting Officer’s Representative\n",
      "Washington Headquarters Service (WHS)\n",
      "Acquisition Directorate (AD)\n",
      "1155 Defense Pentagon Room 5B951\n",
      "Washington, DC 20301-1155\n",
      "Lisa.a.robinson52.civ@mail.mil  \n",
      "(202) 819 - 2679\n",
      "\n",
      "\n",
      "\n",
      "Submitted by:\n",
      "\n",
      "Adrian Nicholas\n",
      "Redhorse Corporation\n",
      "1777 N. Kent St, Suite 1200\n",
      "Arlington, VA 22209 \n",
      "adrian.nicholas@redhorsecorp.com \n",
      "(347) 204-8125\n",
      "Administrative, Financial and Professional Services Support Team\n",
      "Jazmyne Lester\n",
      "Shahzaade Bledsoe\n",
      "Danielle Brown\n",
      "Leah Bernardon\n",
      "Christian Alzona\n",
      "Jadaica Godfrey\n",
      "Erica Sefah \n",
      "Latifah Celey\n",
      "Jerry Medley\n",
      "Noah Stevens\n",
      "Katie Guthrie\n",
      "Nathan Baker\n",
      "Ruju Ghimire\n",
      "\n",
      "Work Performed During MONTH YEAR\n",
      "Administrative Services Support\n",
      "\n",
      "Financial Services Support\n",
      "\n",
      "\n",
      "Professional Services Support \n",
      "Reviewed REO Spend Plan and identified requirements that needed updates.\n",
      "Consolidated and gathered project data from REO Engineers necessary to bring REO Spend plan up to date.\n",
      "Compiled status for Pending Awards Acceptance MIPRs for branch. \n",
      "Reviewed CUI_AMI Report for Mark Center FY 2024 requirements\n",
      "Reviewed the Building- Generated Repair List with Mark Center Project Managers.\n",
      "Supported all weekly required Pentagon & Mark Center meetings. \n",
      "Deliverables Completed\n",
      "IT Capabilities Tasker\n",
      "FOSD Standard Funds Status Tasker\n",
      "Requirement Status (AIM) for FY 2024 Tasker\n",
      "FY 2024 Joint Contact Status Tasker \n",
      "Highlights\n",
      "Completed all required training for FY 2024\n",
      "Completed AIM Training \n",
      "Issues/Resolutions\n",
      "None\n",
      "Planned Work for Next Two Months\n",
      "Professional Services Support\n",
      "Create legend for REO Spend Plan\n",
      "Identify Mark Center FY 2025 requirements. \n",
      "Update the REO Spend Plan with FY 2025 requirements for both Pentagon & Mark Center\n",
      "Draft REO Project priority requirements standards\n",
      "\n",
      "Financial Services Support\n",
      "\n",
      "Administrative Services Support \n",
      "\n",
      "\n",
      "Name | Planned Leave |  For | (CURRENT MONTH)    | Planned Leave |  For | (NEXT MONTH)\n",
      "Danielle Brown | Oct  | 11, 2024\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Recommendations \n",
      "\n",
      "Contractual/Staffing Actions \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "\n",
    "def read_file(file):\n",
    "    if isinstance(file, str):\n",
    "        file_path = file\n",
    "    else:\n",
    "        file_path = file.name\n",
    "\n",
    "    if file_path.endswith('.docx'):\n",
    "        doc = docx.Document(file_path)\n",
    "        full_text = []\n",
    "        for element in doc.element.body:\n",
    "            if element.tag.endswith('p'):\n",
    "                full_text.append(element.text)\n",
    "            elif element.tag.endswith('tbl'):\n",
    "                table = []\n",
    "                for row in element.findall('.//w:tr', namespaces=element.nsmap):\n",
    "                    cells = [cell.text for cell in row.findall('.//w:t', namespaces=element.nsmap)]\n",
    "                    table.append(' | '.join(cells))\n",
    "                full_text.append('\\n'.join(table))\n",
    "        return '\\n'.join(full_text)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./docs/MSR/Danielle Brown_SEPT 2024_MSR.docx\"\n",
    "content = read_file(file_path)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai audio output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-audio-preview\",\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Is a golden retriever a good family dog?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0])\n",
    "\n",
    "wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)\n",
    "with open(\"dog.wav\", \"wb\") as f:\n",
    "    f.write(wav_bytes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import streamlit as st\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to generate audio response\n",
    "def generate_audio_response(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-audio-preview\",\n",
    "        modalities=[\"text\", \"audio\"],\n",
    "        audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0]\n",
    "\n",
    "# Function to decode and save audio\n",
    "def save_audio(audio_data, filename):\n",
    "    wav_bytes = base64.b64decode(audio_data)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(wav_bytes)\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Multi-turn Conversation Bot\")\n",
    "\n",
    "# User input\n",
    "user_input = st.text_input(\"You: \", \"\")\n",
    "\n",
    "if user_input:\n",
    "    # Add user message to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Generate response\n",
    "    response = generate_audio_response(conversation_history)\n",
    "\n",
    "    # Add assistant message to conversation history\n",
    "    conversation_history.append(response.message)\n",
    "\n",
    "    # Save and play audio\n",
    "    audio_filename = f\"{response.message.audio.id}.wav\"\n",
    "    save_audio(response.message.audio.data, audio_filename)\n",
    "    st.audio(audio_filename, format=\"audio/wav\", autoplay=True)\n",
    "\n",
    "    # Display transcript\n",
    "    st.write(\"Assistant: \", response.message.audio.transcript)\n",
    "\n",
    "# Display conversation history\n",
    "st.subheader(\"Conversation History\")\n",
    "for message in conversation_history:\n",
    "    if isinstance(message, dict):  # User message\n",
    "        role = \"You\"\n",
    "        content = message[\"content\"]\n",
    "    else:  # Assistant message\n",
    "        role = \"Assistant\"\n",
    "        content = message.audio.transcript\n",
    "    st.write(f\"{role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elevenlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffe8e309-cb36-462a-a88d-fe7538a01d3a.mp3: A new audio file was saved successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ffe8e309-cb36-462a-a88d-fe7538a01d3a.mp3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import uuid\n",
    "from elevenlabs import VoiceSettings\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "client = ElevenLabs(\n",
    "    api_key=ELEVENLABS_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "def text_to_speech_file(text: str) -> str:\n",
    "    # Calling the text_to_speech conversion API with detailed parameters\n",
    "    response = client.text_to_speech.convert(\n",
    "        voice_id=\"pNInz6obpgDQGcFmaJgB\", # Adam pre-made voice\n",
    "        output_format=\"mp3_22050_32\",\n",
    "        text=text,\n",
    "        model_id=\"eleven_turbo_v2_5\", # use the turbo model for low latency\n",
    "        voice_settings=VoiceSettings(\n",
    "            stability=0.0,\n",
    "            similarity_boost=1.0,\n",
    "            style=0.0,\n",
    "            use_speaker_boost=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # uncomment the line below to play the audio back\n",
    "    # play(response)\n",
    "\n",
    "    # Generating a unique file name for the output MP3 file\n",
    "    save_file_path = f\"{uuid.uuid4()}.mp3\"\n",
    "\n",
    "    # Writing the audio to a file\n",
    "    with open(save_file_path, \"wb\") as f:\n",
    "        for chunk in response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    print(f\"{save_file_path}: A new audio file was saved successfully!\")\n",
    "\n",
    "    # Return the path of the saved audio file\n",
    "    return save_file_path\n",
    "\n",
    "text_to_speech_file(\"Hello World\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
